<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CS229 Cheatsheet - Unsupervised Learning</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <header>
    <h1>CS229 Cheatsheet</h1>
    <h2>Unsupervised Learning</h2>
    <p>Compiled by [Your Name]</p>
  </header>

  <nav>
    <ul>
      <li><a href="#kmeans">K-Means Clustering</a></li>
      <li><a href="#pca">Principal Component Analysis (PCA)</a></li>
      <li><a href="#gaussian">Gaussian Mixture Models</a></li>
    </ul>
  </nav>

  <main>
    <section id="kmeans">
      <h3>K-Means Clustering</h3>
      <p>
        Algorithm:
        <ol>
          <li>Initialize K cluster centroids randomly.</li>
          <li>Assign each data point to the closest centroid.</li>
          <li>Recalculate centroids as the mean of assigned points.</li>
          <li>Repeat until convergence.</li>
        </ol>
      </p>
      <p>
        <strong>Cost Function:</strong><br>
        \( J(c, \mu) = \sum_{i=1}^{m} \|x^{(i)} - \mu_{c^{(i)}}\|^2 \)
      </p>
    </section>

    <section id="pca">
      <h3>Principal Component Analysis (PCA)</h3>
      <p>
        Steps:
        <ul>
          <li>Standardize the dataset.</li>
          <li>Compute the covariance matrix.</li>
          <li>Find eigenvectors and eigenvalues.</li>
          <li>Project data onto top K eigenvectors.</li>
        </ul>
      </p>
    </section>

    <section id="gaussian">
      <h3>Gaussian Mixture Models</h3>
      <p>
        GMM uses a probabilistic model for clustering, assuming data is drawn from a mixture of Gaussian distributions.
      </p>
    </section>
  </main>

  <footer>
    <p>&copy; [Your Name], [Year]. Inspired by Stanford CS229.</p>
  </footer>
</body>
</html>

  
